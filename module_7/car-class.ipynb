{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install Image Data Augmentation\n",
    "!pip install -q git+https://github.com/mjkvaak/ImageDataAugmentor\n",
    "!pip install -q efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import zipfile\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "#models\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "import efficientnet.keras as efn \n",
    "\n",
    "# ImageDataAugmentor\n",
    "from ImageDataAugmentor.image_data_augmentor import *\n",
    "import albumentations as A\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageOps, ImageFilter\n",
    "#увеличим дефолтный размер графиков\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "#графики в svg выглядят более четкими\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "%matplotlib inline\n",
    "\n",
    "print(os.listdir(\"../input\"))\n",
    "print('Python       :', sys.version.split('\\n')[0])\n",
    "print('Numpy        :', np.__version__)\n",
    "print('Tensorflow   :', tf.__version__)\n",
    "print('Keras        :', tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "EPOCHS               = 5  # эпох на обучение\n",
    "BATCH_SIZE           = 64 # уменьшаем batch если сеть большая, иначе не поместится в память на GPU\n",
    "LR                   = 1e-3\n",
    "VAL_SPLIT            = 0.15 # сколько данных выделяем на тест = 15%\n",
    "\n",
    "CLASS_NUM            = 10  # количество классов в нашей задаче\n",
    "IMG_SIZE             = 224 # какого размера подаем изображения в сеть\n",
    "IMG_CHANNELS         = 3   # у RGB 3 канала\n",
    "input_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n",
    "\n",
    "DATA_PATH = '../input/'\n",
    "PATH = \"../working/car/\" # рабочая директория\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Setting seed for reproducibility\n",
    "os.makedirs(PATH,exist_ok=False)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)  \n",
    "PYTHONHASHSEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA / Анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH+\"train.csv\")\n",
    "sample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Extract images')\n",
    "# Will unzip the files so that you can see them..\n",
    "for data_zip in ['train.zip', 'test.zip']:\n",
    "    with zipfile.ZipFile(\"../input/\"+data_zip,\"r\") as z:\n",
    "        z.extractall(PATH)\n",
    "        \n",
    "print(os.listdir(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('random sample')\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "random_image = train_df.sample(n=9)\n",
    "random_image_paths = random_image['Id'].values\n",
    "random_image_cat = random_image['Category'].values\n",
    "\n",
    "for index, path in enumerate(random_image_paths):\n",
    "    im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n",
    "    plt.subplot(3,3, index+1)\n",
    "    plt.imshow(im)\n",
    "    plt.title('Class: '+str(random_image_cat[index]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = PIL.Image.open(PATH+'/train/0/100380.jpg')\n",
    "imgplot = plt.imshow(image)\n",
    "plt.show()\n",
    "image.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATIONS = A.Compose([\n",
    "    A.Transpose(p=0.5),\n",
    "    A.Flip(p=0.5),\n",
    "    A.RandomBrightness(limit=0.2, always_apply=False, p=0.5),\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n",
    "    ],p=1),\n",
    "    A.GaussianBlur(p=0.05),\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "    A.RGBShift(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5), # horizontally flip 50% of all images\n",
    "    A.VerticalFlip(p=0.2), # vertically flip 20% of all images\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, \n",
    "                       scale_limit=0.1, \n",
    "                       rotate_limit=45, \n",
    "                       interpolation=1, \n",
    "                       border_mode=4, \n",
    "                       p=0.5),\n",
    "    A.ElasticTransform(),\n",
    "    A.OneOf([\n",
    "        A.CenterCrop(height=224, width=200),\n",
    "        A.CenterCrop(height=200, width=224)],\n",
    "        p=0.5),\n",
    "    A.FancyPCA(alpha=0.1,always_apply=False, p=0.5),\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataAugmentor(rescale=1./255,\n",
    "                augment=AUGMENTATIONS,                \n",
    "                validation_split=VAL_SPLIT,\n",
    "                seed=RANDOM_SEED\n",
    "                )\n",
    "\n",
    "\n",
    "# wrop data in generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    PATH+'train/',      # директория где расположены папки с картинками \n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training') # set as training data\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    PATH+'train/',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.show_data(rows=1, cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layers(model, fine_tune_at):\n",
    "    \"\"\" Freeze all the layers before the `fine_tune_at` layer \"\"\"\n",
    "    for layer in model.layers[:fine_tune_at]:\n",
    "        layer.trainable =  False\n",
    "\n",
    "def check_layers(m):\n",
    "    \"\"\" Check the trainable status of the individual layers \"\"\"\n",
    "    for layer in model.layers:\n",
    "        print(layer, layer.trainable)        \n",
    "\n",
    "def m_compile(model):\n",
    "    model.compile(loss=\"categorical_crossentropy\", \n",
    "                optimizer=optimizers.Adam(lr=LR), \n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "def m_fit(model):\n",
    "    model.fit_generator(train_generator,\n",
    "        steps_per_epoch = train_generator.samples//train_generator.batch_size,\n",
    "        validation_data = test_generator, \n",
    "        validation_steps = test_generator.samples//test_generator.batch_size,\n",
    "        epochs = EPOCHS,\n",
    "        callbacks = callbacks_list)\n",
    "    \n",
    "        \n",
    "def m_scores(model):\n",
    "    scores = model.evaluate_generator(test_generator, verbose=1)\n",
    "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add checkpoint and manage Learning Rate\n",
    "\n",
    "# add checkpoint to save model progress\n",
    "checkpoint = ModelCheckpoint('best_model.hdf5', \n",
    "                             monitor = ['val_accuracy'], \n",
    "                             verbose = 1 , \n",
    "                             mode = 'max')\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy',\n",
    "                          patience = 4,                          \n",
    "                          restore_best_weights = True)\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.25,\n",
    "                              patience=2,\n",
    "                              min_lr=0.0000001,\n",
    "                              verbose=1,\n",
    "                              mode='auto')\n",
    "\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pre-trained model\n",
    "\n",
    "# https://pypi.org/project/efficientnet/\n",
    "efn_model = efn.EfficientNetB7(weights='imagenet', \n",
    "                                include_top=False, \n",
    "                                input_shape = input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "#efn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model=Sequential()\n",
    "model.add(efn_model) # Add the efn convolutional base model\n",
    "\n",
    "# Add new layers\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "\"\"\"\n",
    "model.add(Conv2D(16, kernel_size=3, strides=1, padding=\"same\", input_shape=(32, 32, 3) ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=3, strides=1, padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))    \n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, strides=1, padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=3, strides=1, padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\"\"\"\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(CLASS_NUM, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Freeze the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the layers\n",
    "for layer in efn_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "#check_layers(efn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_compile(model)\n",
    "m_fit(model)\n",
    "model.load_weights('best_model.hdf5')\n",
    "m_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. defrost 50% of the pre-trained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/guides/transfer_learning/\n",
    "efn_model.trainable = True\n",
    "fine_tune_at = len(efn_model.layers)//2 # Fine-tune from this layer onwards\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "LR  = 1e-4\n",
    "\n",
    "freeze_layers(efn_model, fine_tune_at) # freeze 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_compile(model)\n",
    "m_fit(model)\n",
    "model.load_weights('best_model.hdf5')\n",
    "m_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. complete weights defrosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efn_model.trainable = True\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_compile(model)\n",
    "m_fit(model)\n",
    "model.load_weights('best_model.hdf5')\n",
    "m_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. change image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efn_model.trainable = True\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "LR = 1e-5\n",
    "IMG_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_compile(model)\n",
    "m_fit(model)\n",
    "model.load_weights('best_model.hdf5')\n",
    "m_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataAugmentor(rescale=1./255)\n",
    "\n",
    "test_sub_generator = test_datagen.flow_from_dataframe( \n",
    "    dataframe=sample_submission,\n",
    "    directory=PATH+'test_upload/',\n",
    "    x_col=\"Id\",\n",
    "    y_col=None,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub_generator.reset()\n",
    "predictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \n",
    "predictions = np.argmax(predictions, axis=-1) #multiple categories\n",
    "label_map = (train_generator.class_indices)\n",
    "label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n",
    "predictions = [label_map[k] for k in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_with_dir=test_sub_generator.filenames\n",
    "submission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\n",
    "submission['Id'] = submission['Id'].replace('test_upload/','')\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Save submit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Clean PATH\n",
    "import shutil\n",
    "shutil.rmtree(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что можно сделать, чтоб улучшить результат:\n",
    "* Подобрать LR, optimizer, loss\n",
    "* Добавить аугментацию\n",
    "* Поиграться с архитектурой\n",
    "* Подобрать другие переменные (размер картинки, батч и тп)\n",
    "* Добавить политику обучения\n",
    "* Добавить TTA\n",
    "* Найти и обучиться на других внешних данных\n",
    "* Построить ансамбль из разных архитектур\n",
    "\n",
    "### Удачи в соревновании!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
